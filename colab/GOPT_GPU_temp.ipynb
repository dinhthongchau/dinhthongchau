{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GOPT_GPU",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dinhthongchau/dinhthongchau/blob/main/colab/GOPT_GPU_temp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [Transformer-Based Multi-Aspect Multi-Granularity Non-Native English Speaker Pronunciation Assessment](https://arxiv.org/abs/2205.03432)\n",
        "\n",
        "- This colab script contains the official implementation and pretrained model (in PyTorch) of the **Goodness Of Pronunciation Feature-Based Transformer (GOPT)** proposed in the ICASSP 2022 paper [Transformer-Based Multi-Aspect Multi-Granularity Non-native English Speaker Pronunciation Assessment](https://ieeexplore.ieee.org/document/9746743) (Yuan Gong, Ziyi Chen, Iek-Heng Chu, Peng Chang, James Glass; MIT & PAII).\n",
        "\n",
        "- Please cite our paper if you find this repository useful.\n",
        "\n",
        " - ```\n",
        "@INPROCEEDINGS{gong_gopt,\n",
        "  author={Gong, Yuan and Chen, Ziyi and Chu, Iek-Heng and Chang, Peng and Glass, James},\n",
        "  booktitle={ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},\n",
        "  title={Transformer-Based Multi-Aspect Multi-Granularity Non-Native English Speaker Pronunciation Assessment},\n",
        "  year={2022},\n",
        "  pages={7262-7266},\n",
        "  doi={10.1109/ICASSP43922.2022.9746743}}\n",
        "```\n",
        "\n",
        "\n",
        "- For more information, please check https://github.com/YuanGongND/gopt"
      ],
      "metadata": {
        "collapsed": false,
        "id": "hbpzp6zbFCEV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 1. Automatically load the Kaldi GOP feature.\n",
        "Note: this skips the Kaldi GOP feature extraction part. If you are interested in the feature extraction, please check our GitHub on how to do that."
      ],
      "metadata": {
        "id": "kKg-0_ISru4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "print('current working dir is ' + os.getcwd())\n",
        "data_dir = os.getcwd() + '/gopt'\n",
        "if os.path.exists(data_dir) == True:\n",
        "    print('data path already exists')\n",
        "else:\n",
        "    os.makedirs(data_dir)\n",
        "\n",
        "if os.path.exists(os.getcwd() + '/gopt/data.zip') == False:\n",
        "  print('Downloading the intermediate GOP feature, please be patient.')\n",
        "  os.system('wget https://www.dropbox.com/s/zc6o1d8rqq28vci/data.zip?dl=1 -O ' + os.getcwd() +'/gopt/data.zip')\n",
        "  os.system('unzip -q ' + os.getcwd() + '/gopt/data.zip -d ' + os.getcwd() + '/gopt/')\n",
        "  print('Kaldi GOP features loaded at ' + os.getcwd() + '/gopt/, check the fold button on the left hand for details.')\n",
        "else:\n",
        "  print('Kaldi GOP features already loadedat ' + os.getcwd() + '/gopt/, check the fold button on the left hand for details.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqFES3mXuA2n",
        "outputId": "89c2e65a-5ba8-41be-db03-eb546bc4ef18"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current working dir is /content\n",
            "Downloading the intermediate GOP feature, please be patient.\n",
            "Kaldi GOP features loaded at /content/gopt/, check the fold button on the left hand for details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2. Build the GOPT model."
      ],
      "metadata": {
        "id": "366AJg7CpXjP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "I7bNAIRSoKDp"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import warnings\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "# code from the t2t-vit paper\n",
        "def get_sinusoid_encoding(n_position, d_hid):\n",
        "    ''' Sinusoid position encoding table '''\n",
        "\n",
        "    def get_position_angle_vec(position):\n",
        "        return [position / np.power(10000, 2 * (hid_j // 2) / d_hid) for hid_j in range(d_hid)]\n",
        "\n",
        "    sinusoid_table = np.array([get_position_angle_vec(pos_i) for pos_i in range(n_position)])\n",
        "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])  # dim 2i\n",
        "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])  # dim 2i+1\n",
        "\n",
        "    return torch.FloatTensor(sinusoid_table).unsqueeze(0)\n",
        "\n",
        "\n",
        "def _no_grad_trunc_normal_(tensor, mean, std, a, b):\n",
        "    # Cut & paste from PyTorch official master until it's in a few official releases - RW\n",
        "    # Method based on https://people.sc.fsu.edu/~jburkardt/presentations/truncated_normal.pdf\n",
        "    def norm_cdf(x):\n",
        "        # Computes standard normal cumulative distribution function\n",
        "        return (1. + math.erf(x / math.sqrt(2.))) / 2.\n",
        "\n",
        "    if (mean < a - 2 * std) or (mean > b + 2 * std):\n",
        "        warnings.warn(\"mean is more than 2 std from [a, b] in nn.init.trunc_normal_. \"\n",
        "                      \"The distribution of values may be incorrect.\",\n",
        "                      stacklevel=2)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Values are generated by using a truncated uniform distribution and\n",
        "        # then using the inverse CDF for the normal distribution.\n",
        "        # Get upper and lower cdf values\n",
        "        l = norm_cdf((a - mean) / std)\n",
        "        u = norm_cdf((b - mean) / std)\n",
        "\n",
        "        # Uniformly fill tensor with values from [l, u], then translate to\n",
        "        # [2l-1, 2u-1].\n",
        "        tensor.uniform_(2 * l - 1, 2 * u - 1)\n",
        "\n",
        "        # Use inverse cdf transform for normal distribution to get truncated\n",
        "        # standard normal\n",
        "        tensor.erfinv_()\n",
        "\n",
        "        # Transform to proper mean, std\n",
        "        tensor.mul_(std * math.sqrt(2.))\n",
        "        tensor.add_(mean)\n",
        "\n",
        "        # Clamp to ensure it's in the proper range\n",
        "        tensor.clamp_(min=a, max=b)\n",
        "        return tensor\n",
        "\n",
        "def trunc_normal_(tensor, mean=0., std=1., a=-2., b=2.):\n",
        "    return _no_grad_trunc_normal_(tensor, mean, std, a, b)\n",
        "\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, num_heads=8, qkv_bias=False, qk_scale=None, attn_drop=0., proj_drop=0.):\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        head_dim = dim // num_heads\n",
        "        # NOTE scale factor was wrong in my original version, can set manually to be compat with prev weights\n",
        "        self.scale = qk_scale or head_dim ** -0.5\n",
        "\n",
        "        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
        "        self.attn_drop = nn.Dropout(attn_drop)\n",
        "        self.proj = nn.Linear(dim, dim)\n",
        "        self.proj_drop = nn.Dropout(proj_drop)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, C = x.shape\n",
        "        #print(C)\n",
        "        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2]   # make torchscript happy (cannot use tensor as tuple)\n",
        "\n",
        "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
        "        attn = attn.softmax(dim=-1)\n",
        "        attn = self.attn_drop(attn)\n",
        "\n",
        "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
        "        x = self.proj(x)\n",
        "        x = self.proj_drop(x)\n",
        "        return x\n",
        "\n",
        "class Mlp(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.):\n",
        "        super().__init__()\n",
        "        out_features = out_features or in_features\n",
        "        hidden_features = hidden_features or in_features\n",
        "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
        "        self.act = act_layer()\n",
        "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
        "        self.drop = nn.Dropout(drop)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.drop(x)\n",
        "        return x\n",
        "\n",
        "class Block(nn.Module):\n",
        "\n",
        "    def __init__(self, dim, num_heads, mlp_ratio=4., qkv_bias=False, qk_scale=None, drop=0., attn_drop=0.,\n",
        "                 drop_path=0., act_layer=nn.GELU, norm_layer=nn.LayerNorm):\n",
        "        super().__init__()\n",
        "        self.norm1 = norm_layer(dim)\n",
        "        self.attn = Attention(\n",
        "            dim, num_heads=num_heads, qkv_bias=qkv_bias, qk_scale=qk_scale, attn_drop=attn_drop, proj_drop=drop)\n",
        "        # NOTE: drop path for stochastic depth, we shall see if this is better than dropout here\n",
        "        self.drop_path = nn.Identity()\n",
        "        self.norm2 = norm_layer(dim)\n",
        "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
        "        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.drop_path(self.attn(self.norm1(x)))\n",
        "        x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
        "        return x\n",
        "\n",
        "# standard GOPT model proposed in the paper\n",
        "class GOPT(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads, depth, input_dim=84):\n",
        "        super().__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.embed_dim = embed_dim\n",
        "        # Transformer encode blocks\n",
        "        self.blocks = nn.ModuleList([Block(dim=embed_dim, num_heads=num_heads) for i in range(depth)])\n",
        "\n",
        "        # sin pos embedding or learnable pos embedding, 55 = 50 sequence length + 5 utt-level cls tokens\n",
        "        #self.pos_embed = nn.Parameter(get_sinusoid_encoding(55, self.embed_dim) * 0.1, requires_grad=True)\n",
        "        self.pos_embed = nn.Parameter(torch.zeros(1, 55, self.embed_dim))\n",
        "        trunc_normal_(self.pos_embed, std=.02)\n",
        "\n",
        "        # for phone classification\n",
        "        self.in_proj = nn.Linear(self.input_dim, embed_dim)\n",
        "        self.mlp_head_phn = nn.Sequential(nn.LayerNorm(embed_dim), nn.Linear(embed_dim, 1))\n",
        "\n",
        "        # for word classification, 1=accuracy, 2=stress, 3=total\n",
        "        self.mlp_head_word1 = nn.Sequential(nn.LayerNorm(embed_dim), nn.Linear(embed_dim, 1))\n",
        "        self.mlp_head_word2 = nn.Sequential(nn.LayerNorm(embed_dim), nn.Linear(embed_dim, 1))\n",
        "        self.mlp_head_word3 = nn.Sequential(nn.LayerNorm(embed_dim), nn.Linear(embed_dim, 1))\n",
        "\n",
        "        # canonical phone projection, assume there are 40 phns\n",
        "        self.phn_proj = nn.Linear(40, embed_dim)\n",
        "\n",
        "        # utterance level, 1=accuracy, 2=completeness, 3=fluency, 4=prosodic, 5=total score\n",
        "        self.cls_token1 = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
        "        self.mlp_head_utt1 = nn.Sequential(nn.LayerNorm(embed_dim), nn.Linear(embed_dim, 1))\n",
        "        self.cls_token2 = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
        "        self.mlp_head_utt2 = nn.Sequential(nn.LayerNorm(embed_dim), nn.Linear(embed_dim, 1))\n",
        "        self.cls_token3 = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
        "        self.mlp_head_utt3 = nn.Sequential(nn.LayerNorm(embed_dim), nn.Linear(embed_dim, 1))\n",
        "        self.cls_token4 = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
        "        self.mlp_head_utt4 = nn.Sequential(nn.LayerNorm(embed_dim), nn.Linear(embed_dim, 1))\n",
        "        self.cls_token5 = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
        "        self.mlp_head_utt5 = nn.Sequential(nn.LayerNorm(embed_dim), nn.Linear(embed_dim, 1))\n",
        "\n",
        "        # initialize the cls tokens\n",
        "        trunc_normal_(self.cls_token1, std=.02)\n",
        "        trunc_normal_(self.cls_token2, std=.02)\n",
        "        trunc_normal_(self.cls_token3, std=.02)\n",
        "        trunc_normal_(self.cls_token4, std=.02)\n",
        "        trunc_normal_(self.cls_token5, std=.02)\n",
        "\n",
        "    # x shape in [batch_size, sequence_len, feat_dim]\n",
        "    # phn in [batch_size, seq_len]\n",
        "    def forward(self, x, phn):\n",
        "\n",
        "        # batch size\n",
        "        B = x.shape[0]\n",
        "\n",
        "        # phn_one_hot in shape [batch_size, seq_len, feat_dim]\n",
        "        phn_one_hot = torch.nn.functional.one_hot(phn.long()+1, num_classes=40).float()\n",
        "        # phn_embed in shape [batch_size, seq_len, embed_dim]\n",
        "        phn_embed = self.phn_proj(phn_one_hot)\n",
        "\n",
        "        # if the input dimension is different from the Transformer embedding dimension, project the input to same dim\n",
        "        if self.embed_dim != self.input_dim:\n",
        "            x = self.in_proj(x)\n",
        "\n",
        "        x = x + phn_embed\n",
        "\n",
        "        cls_token1 = self.cls_token1.expand(B, -1, -1)\n",
        "        cls_token2 = self.cls_token2.expand(B, -1, -1)\n",
        "        cls_token3 = self.cls_token3.expand(B, -1, -1)\n",
        "        cls_token4 = self.cls_token4.expand(B, -1, -1)\n",
        "        cls_token5 = self.cls_token5.expand(B, -1, -1)\n",
        "\n",
        "        x = torch.cat((cls_token1, cls_token2, cls_token3, cls_token4, cls_token5, x), dim=1)\n",
        "\n",
        "        x = x + self.pos_embed\n",
        "\n",
        "        # forward to the Transformer encoder\n",
        "        for blk in self.blocks:\n",
        "            x = blk(x)\n",
        "\n",
        "        # the first 5 tokens are utterance-level cls tokens, i.e., accuracy, completeness, fluency, prosodic, total scores\n",
        "        u1 = self.mlp_head_utt1(x[:, 0])\n",
        "        u2 = self.mlp_head_utt2(x[:, 1])\n",
        "        u3 = self.mlp_head_utt3(x[:, 2])\n",
        "        u4 = self.mlp_head_utt4(x[:, 3])\n",
        "        u5 = self.mlp_head_utt5(x[:, 4])\n",
        "\n",
        "        # 6th-end tokens are phone score tokens\n",
        "        p = self.mlp_head_phn(x[:, 5:])\n",
        "\n",
        "        # word score is propagated to phone-level, so word output is also at phone-level.\n",
        "        # but different mlp heads are used, 1 = accuracy, 2 = stress, 3 = total\n",
        "        w1 = self.mlp_head_word1(x[:, 5:])\n",
        "        w2 = self.mlp_head_word2(x[:, 5:])\n",
        "        w3 = self.mlp_head_word3(x[:, 5:])\n",
        "        return u1, u2, u3, u4, u5, p, w1, w2, w3"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3. Load the GOP features."
      ],
      "metadata": {
        "id": "Xf9OIkR1pvE1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "class GoPDataset(Dataset):\n",
        "    def __init__(self, set, am='librispeech'):\n",
        "        # normalize the input to 0 mean and unit std.\n",
        "        if am=='librispeech':\n",
        "            dir='seq_data_librispeech'\n",
        "            norm_mean, norm_std = 3.203, 4.045\n",
        "        elif am=='paiia':\n",
        "            dir='seq_data_paiia'\n",
        "            norm_mean, norm_std = -0.652, 9.737\n",
        "        elif am=='paiib':\n",
        "            dir='seq_data_paiib'\n",
        "            norm_mean, norm_std = -0.516, 9.247\n",
        "        else:\n",
        "            raise ValueError('Acoustic Model Unrecognized.')\n",
        "\n",
        "        if set == 'train':\n",
        "            self.feat = torch.tensor(np.load(os.getcwd()+'/gopt/'+dir+'/tr_feat.npy'), dtype=torch.float)\n",
        "            self.phn_label = torch.tensor(np.load(os.getcwd()+'/gopt/'+dir+'/tr_label_phn.npy'), dtype=torch.float)\n",
        "            self.utt_label = torch.tensor(np.load(os.getcwd()+'/gopt/'+dir+'/tr_label_utt.npy'), dtype=torch.float)\n",
        "            self.word_label = torch.tensor(np.load(os.getcwd()+'/gopt/'+dir+'/tr_label_word.npy'), dtype=torch.float)\n",
        "        elif set == 'test':\n",
        "            self.feat = torch.tensor(np.load(os.getcwd()+'/gopt/'+dir+'/te_feat.npy'), dtype=torch.float)\n",
        "            self.phn_label = torch.tensor(np.load(os.getcwd()+'/gopt/'+dir+'/te_label_phn.npy'), dtype=torch.float)\n",
        "            self.utt_label = torch.tensor(np.load(os.getcwd()+'/gopt/'+dir+'/te_label_utt.npy'), dtype=torch.float)\n",
        "            self.word_label = torch.tensor(np.load(os.getcwd()+'/gopt/'+dir+'/te_label_word.npy'), dtype=torch.float)\n",
        "\n",
        "        # normalize the GOP feature using the training set mean and std (only count the valid token features, exclude the padded tokens).\n",
        "        self.feat = self.norm_valid(self.feat, norm_mean, norm_std)\n",
        "\n",
        "        # normalize the utt_label to 0-2 (same with phn score range)\n",
        "        self.utt_label = self.utt_label / 5\n",
        "        # the last dim is word_id, so not normalizing\n",
        "        self.word_label[:, :, 0:3] = self.word_label[:, :, 0:3] / 5\n",
        "        self.phn_label[:, :, 1] = self.phn_label[:, :, 1]\n",
        "\n",
        "    # only normalize valid tokens, not padded token\n",
        "    def norm_valid(self, feat, norm_mean, norm_std):\n",
        "        norm_feat = torch.zeros_like(feat)\n",
        "        for i in range(feat.shape[0]):\n",
        "            for j in range(feat.shape[1]):\n",
        "                if feat[i, j, 0] != 0:\n",
        "                    norm_feat[i, j, :] = (feat[i, j, :] - norm_mean) / norm_std\n",
        "                else:\n",
        "                    break\n",
        "        return norm_feat\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.feat.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # feat, phn_label, phn_id, utt_label, word_label\n",
        "        return self.feat[idx, :], self.phn_label[idx, :, 1], self.phn_label[idx, :, 0], self.utt_label[idx, :], self.word_label[idx, :]"
      ],
      "metadata": {
        "id": "Z5z2U2dTpuNQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4. Build the training and evaluation pipeline."
      ],
      "metadata": {
        "id": "dXHf-H1jvzOS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "import time\n",
        "import argparse\n",
        "\n",
        "print(\"I am process %s, running on %s: starting (%s)\" % (os.getpid(), os.uname()[1], time.asctime()))\n",
        "parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
        "parser.add_argument(\"--exp-dir\", type=str, default=os.getcwd()+\"/exp/\", help=\"directory to dump experiments\")\n",
        "parser.add_argument('--lr', '--learning-rate', default=1e-3, type=float, metavar='LR', help='initial learning rate')\n",
        "parser.add_argument(\"--n-epochs\", type=int, default=50, help=\"number of maximum training epochs\")\n",
        "parser.add_argument(\"--goptdepth\", type=int, default=3, help=\"depth of gopt models\")\n",
        "parser.add_argument(\"--goptheads\", type=int, default=1, help=\"heads of gopt models\")\n",
        "parser.add_argument(\"--batch_size\", type=int, default=25, help=\"training batch size\")\n",
        "parser.add_argument(\"--embed_dim\", type=int, default=24, help=\"gopt transformer embedding dimension\")\n",
        "parser.add_argument(\"--loss_w_phn\", type=float, default=1, help=\"weight for phoneme-level loss\")\n",
        "parser.add_argument(\"--loss_w_word\", type=float, default=1, help=\"weight for word-level loss\")\n",
        "parser.add_argument(\"--loss_w_utt\", type=float, default=1, help=\"weight for utterance-level loss\")\n",
        "parser.add_argument(\"--model\", type=str, default='gopt', help=\"name of the model\")\n",
        "parser.add_argument(\"--am\", type=str, default='paiia', help=\"name of the acoustic models\")\n",
        "parser.add_argument(\"--noise\", type=float, default=0., help=\"the scale of random noise added on the input GoP feature\")\n",
        "\n",
        "# just to generate the header for the result.csv\n",
        "def gen_result_header():\n",
        "    phn_header = ['epoch', 'phone_train_mse', 'phone_train_pcc', 'phone_test_mse', 'phone_test_pcc', 'learning rate']\n",
        "    utt_header_set = ['utt_train_mse', 'utt_train_pcc', 'utt_test_mse', 'utt_test_pcc']\n",
        "    utt_header_score = ['accuracy', 'completeness', 'fluency', 'prosodic', 'total']\n",
        "    word_header_set = ['word_train_pcc', 'word_test_pcc']\n",
        "    word_header_score = ['accuracy', 'stress', 'total']\n",
        "    utt_header, word_header = [], []\n",
        "    for dset in utt_header_set:\n",
        "        utt_header = utt_header + [dset+'_'+x for x in utt_header_score]\n",
        "    for dset in word_header_set:\n",
        "        word_header = word_header + [dset+'_'+x for x in word_header_score]\n",
        "    header = phn_header + utt_header + word_header\n",
        "    return header\n",
        "\n",
        "def train(audio_model, train_loader, test_loader, args):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print('running on ' + str(device))\n",
        "\n",
        "    # best_cum_mAP is checkpoint ensemble from the first epoch to the best epoch\n",
        "    best_epoch, best_mse = 0, 999\n",
        "    global_step, epoch = 0, 0\n",
        "    exp_dir = args.exp_dir\n",
        "\n",
        "    if not isinstance(audio_model, nn.DataParallel):\n",
        "        audio_model = nn.DataParallel(audio_model)\n",
        "\n",
        "    audio_model = audio_model.to(device)\n",
        "    # Set up the optimizer\n",
        "    trainables = [p for p in audio_model.parameters() if p.requires_grad]\n",
        "    print('Total parameter number is : {:.3f} k'.format(sum(p.numel() for p in audio_model.parameters()) / 1e3))\n",
        "    print('Total trainable parameter number is : {:.3f} k'.format(sum(p.numel() for p in trainables) / 1e3))\n",
        "    optimizer = torch.optim.Adam(trainables, args.lr, weight_decay=5e-7, betas=(0.95, 0.999))\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, list(range(10, 100, 5)), gamma=0.5, last_epoch=-1)\n",
        "\n",
        "    loss_fn = nn.MSELoss()\n",
        "\n",
        "    print(\"current #steps=%s, #epochs=%s\" % (global_step, epoch))\n",
        "    print(\"start training...\")\n",
        "    result = np.zeros([args.n_epochs, 32])\n",
        "\n",
        "    while epoch < args.n_epochs:\n",
        "        audio_model.train()\n",
        "        for i, (audio_input, phn_label, phns, utt_label, word_label) in enumerate(train_loader):\n",
        "\n",
        "            audio_input = audio_input.to(device, non_blocking=True)\n",
        "            phn_label = phn_label.to(device, non_blocking=True)\n",
        "            utt_label = utt_label.to(device, non_blocking=True)\n",
        "            word_label = word_label.to(device, non_blocking=True)\n",
        "\n",
        "            # warmup\n",
        "            warm_up_step = 100\n",
        "            if global_step <= warm_up_step and global_step % 5 == 0:\n",
        "                warm_lr = (global_step / warm_up_step) * args.lr\n",
        "                for param_group in optimizer.param_groups:\n",
        "                    param_group['lr'] = warm_lr\n",
        "                #print('warm-up learning rate is {:f}'.format(optimizer.param_groups[0]['lr']))\n",
        "\n",
        "            # add random noise for augmentation.\n",
        "            noise = (torch.rand([audio_input.shape[0], audio_input.shape[1], audio_input.shape[2]]) - 1) * args.noise\n",
        "            noise = noise.to(device, non_blocking=True)\n",
        "            audio_input = audio_input + noise\n",
        "\n",
        "            #print(phns.shape)\n",
        "            u1, u2, u3, u4, u5, p, w1, w2, w3 = audio_model(audio_input, phns)\n",
        "\n",
        "            # filter out the padded tokens, only calculate the loss based on the valid tokens\n",
        "            # < 0 is a flag of padded tokens\n",
        "            mask = (phn_label>=0)\n",
        "            p = p.squeeze(2)\n",
        "            p = p * mask\n",
        "            phn_label = phn_label * mask\n",
        "\n",
        "            loss_phn = loss_fn(p, phn_label)\n",
        "\n",
        "            # avoid the 0 losses of the padded tokens impacting the performance\n",
        "            loss_phn = loss_phn * (mask.shape[0] * mask.shape[1]) / torch.sum(mask)\n",
        "\n",
        "            # utterance level loss, also mse\n",
        "            utt_preds = torch.cat((u1, u2, u3, u4, u5), dim=1)\n",
        "            loss_utt = loss_fn(utt_preds ,utt_label)\n",
        "\n",
        "            # word level loss\n",
        "            word_label = word_label[:, :, 0:3]\n",
        "            mask = (word_label>=0)\n",
        "            word_pred = torch.cat((w1,w2,w3), dim=2)\n",
        "            word_pred = word_pred * mask\n",
        "            word_label = word_label * mask\n",
        "            loss_word = loss_fn(word_pred, word_label)\n",
        "            loss_word = loss_word * (mask.shape[0] * mask.shape[1] * mask.shape[2]) / torch.sum(mask)\n",
        "\n",
        "            loss = args.loss_w_phn * loss_phn + args.loss_w_utt * loss_utt + args.loss_w_word * loss_word\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            global_step += 1\n",
        "\n",
        "        print('start validation of epoch {:d}'.format(epoch))\n",
        "\n",
        "        # ensemble results\n",
        "        # don't save prediction for the training set\n",
        "        tr_mse, tr_corr, tr_utt_mse, tr_utt_corr, tr_word_mse, tr_word_corr = validate(audio_model, train_loader, args, -1)\n",
        "        te_mse, te_corr, te_utt_mse, te_utt_corr, te_word_mse, te_word_corr = validate(audio_model, test_loader, args, best_mse)\n",
        "\n",
        "        print('Phone: Test MSE: {:.3f}, CORR: {:.3f}'.format(te_mse.item(), te_corr))\n",
        "        print('Utterance:, ACC: {:.3f}, COM: {:.3f}, FLU: {:.3f}, PROC: {:.3f}, Total: {:.3f}'.format(te_utt_corr[0], te_utt_corr[1], te_utt_corr[2], te_utt_corr[3], te_utt_corr[4]))\n",
        "        print('Word:, ACC: {:.3f}, Stress: {:.3f}, Total: {:.3f}'.format(te_word_corr[0], te_word_corr[1], te_word_corr[2]))\n",
        "\n",
        "        result[epoch, :6] = [epoch, tr_mse, tr_corr, te_mse, te_corr, optimizer.param_groups[0]['lr']]\n",
        "\n",
        "        result[epoch, 6:26] = np.concatenate([tr_utt_mse, tr_utt_corr, te_utt_mse, te_utt_corr])\n",
        "\n",
        "        result[epoch, 26:32] = np.concatenate([tr_word_corr, te_word_corr])\n",
        "\n",
        "        header = ','.join(gen_result_header())\n",
        "        np.savetxt(exp_dir + '/result.csv', result, delimiter=',', header=header, comments='')\n",
        "        print('-------------------validation finished-------------------')\n",
        "\n",
        "        if te_mse < best_mse:\n",
        "            best_mse = te_mse\n",
        "            best_epoch = epoch\n",
        "\n",
        "        if best_epoch == epoch:\n",
        "            if os.path.exists(\"%s/models/\" % (exp_dir)) == False:\n",
        "                os.mkdir(\"%s/models\" % (exp_dir))\n",
        "            torch.save(audio_model.state_dict(), \"%s/models/best_audio_model.pth\" % (exp_dir))\n",
        "\n",
        "        if global_step > warm_up_step:\n",
        "            scheduler.step()\n",
        "\n",
        "        #print('Epoch-{0} lr: {1}'.format(epoch, optimizer.param_groups[0]['lr']))\n",
        "        epoch += 1\n",
        "\n",
        "def validate(audio_model, val_loader, args, best_mse):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    if not isinstance(audio_model, nn.DataParallel):\n",
        "        audio_model = nn.DataParallel(audio_model)\n",
        "    audio_model = audio_model.to(device)\n",
        "    audio_model.eval()\n",
        "\n",
        "    A_phn, A_phn_target = [], []\n",
        "    A_u1, A_u2, A_u3, A_u4, A_u5, A_utt_target = [], [], [], [], [], []\n",
        "    A_w1, A_w2, A_w3, A_word_target = [], [], [], []\n",
        "    with torch.no_grad():\n",
        "        for i, (audio_input, phn_label, phns, utt_label, word_label) in enumerate(val_loader):\n",
        "            audio_input = audio_input.to(device)\n",
        "\n",
        "            # compute output\n",
        "            u1, u2, u3, u4, u5, p, w1, w2, w3 = audio_model(audio_input, phns)\n",
        "            p = p.to('cpu').detach()\n",
        "            u1, u2, u3, u4, u5 = u1.to('cpu').detach(), u2.to('cpu').detach(), u3.to('cpu').detach(), u4.to('cpu').detach(), u5.to('cpu').detach()\n",
        "            w1, w2, w3 = w1.to('cpu').detach(), w2.to('cpu').detach(), w3.to('cpu').detach()\n",
        "\n",
        "            A_phn.append(p)\n",
        "            A_phn_target.append(phn_label)\n",
        "\n",
        "            A_u1.append(u1)\n",
        "            A_u2.append(u2)\n",
        "            A_u3.append(u3)\n",
        "            A_u4.append(u4)\n",
        "            A_u5.append(u5)\n",
        "            A_utt_target.append(utt_label)\n",
        "\n",
        "            A_w1.append(w1)\n",
        "            A_w2.append(w2)\n",
        "            A_w3.append(w3)\n",
        "            A_word_target.append(word_label)\n",
        "\n",
        "        # phone level\n",
        "        A_phn, A_phn_target  = torch.cat(A_phn), torch.cat(A_phn_target)\n",
        "\n",
        "        # utterance level\n",
        "        A_u1, A_u2, A_u3, A_u4, A_u5, A_utt_target = torch.cat(A_u1), torch.cat(A_u2), torch.cat(A_u3), torch.cat(A_u4), torch.cat(A_u5), torch.cat(A_utt_target)\n",
        "\n",
        "        # word level\n",
        "        A_w1, A_w2, A_w3, A_word_target = torch.cat(A_w1), torch.cat(A_w2), torch.cat(A_w3), torch.cat(A_word_target)\n",
        "\n",
        "        # get the scores\n",
        "        phn_mse, phn_corr = valid_phn(A_phn, A_phn_target)\n",
        "\n",
        "        A_utt = torch.cat((A_u1, A_u2, A_u3, A_u4, A_u5), dim=1)\n",
        "        utt_mse, utt_corr = valid_utt(A_utt, A_utt_target)\n",
        "\n",
        "        A_word = torch.cat((A_w1, A_w2, A_w3), dim=2)\n",
        "        word_mse, word_corr, valid_word_pred, valid_word_target = valid_word(A_word, A_word_target)\n",
        "\n",
        "        if phn_mse < best_mse:\n",
        "            print('new best phn mse {:.3f}, now saving predictions.'.format(phn_mse))\n",
        "\n",
        "            # create the directory\n",
        "            if os.path.exists(args.exp_dir + '/preds') == False:\n",
        "                os.mkdir(args.exp_dir + '/preds')\n",
        "\n",
        "            # saving the phn target, only do once\n",
        "            if os.path.exists(args.exp_dir + '/preds/phn_target.npy') == False:\n",
        "                np.save(args.exp_dir + '/preds/phn_target.npy', A_phn_target)\n",
        "                np.save(args.exp_dir + '/preds/word_target.npy', valid_word_target)\n",
        "                np.save(args.exp_dir + '/preds/utt_target.npy', A_utt_target)\n",
        "\n",
        "            np.save(args.exp_dir + '/preds/phn_pred.npy', A_phn)\n",
        "            np.save(args.exp_dir + '/preds/word_pred.npy', valid_word_pred)\n",
        "            np.save(args.exp_dir + '/preds/utt_pred.npy', A_utt)\n",
        "\n",
        "    return phn_mse, phn_corr, utt_mse, utt_corr, word_mse, word_corr\n",
        "\n",
        "def valid_phn(audio_output, target):\n",
        "    valid_token_pred = []\n",
        "    valid_token_target = []\n",
        "    audio_output = audio_output.squeeze(2)\n",
        "    for i in range(audio_output.shape[0]):\n",
        "        for j in range(audio_output.shape[1]):\n",
        "            # only count valid tokens, not padded tokens (represented by negative values)\n",
        "            if target[i, j] >= 0:\n",
        "                valid_token_pred.append(audio_output[i, j])\n",
        "                valid_token_target.append(target[i, j])\n",
        "    valid_token_target = np.array(valid_token_target)\n",
        "    valid_token_pred = np.array(valid_token_pred)\n",
        "\n",
        "    valid_token_mse = np.mean((valid_token_target - valid_token_pred) ** 2)\n",
        "    corr = np.corrcoef(valid_token_pred, valid_token_target)[0, 1]\n",
        "    return valid_token_mse, corr\n",
        "\n",
        "def valid_utt(audio_output, target):\n",
        "    mse = []\n",
        "    corr = []\n",
        "    for i in range(5):\n",
        "        cur_mse = np.mean(((audio_output[:, i] - target[:, i]) ** 2).numpy())\n",
        "        cur_corr = np.corrcoef(audio_output[:, i], target[:, i])[0, 1]\n",
        "        mse.append(cur_mse)\n",
        "        corr.append(cur_corr)\n",
        "    return mse, corr\n",
        "\n",
        "def valid_word(audio_output, target):\n",
        "    word_id = target[:, :, -1]\n",
        "    target = target[:, :, 0:3]\n",
        "\n",
        "    valid_token_pred = []\n",
        "    valid_token_target = []\n",
        "\n",
        "    # unique, counts = np.unique(np.array(target), return_counts=True)\n",
        "    # print(dict(zip(unique, counts)))\n",
        "\n",
        "    # for each utterance\n",
        "    for i in range(target.shape[0]):\n",
        "        prev_w_id = 0\n",
        "        start_id = 0\n",
        "        # for each token\n",
        "        for j in range(target.shape[1]):\n",
        "            cur_w_id = word_id[i, j].int()\n",
        "            # if a new word\n",
        "            if cur_w_id != prev_w_id:\n",
        "                # average each phone belongs to the word\n",
        "                valid_token_pred.append(np.mean(audio_output[i, start_id: j, :].numpy(), axis=0))\n",
        "                valid_token_target.append(np.mean(target[i, start_id: j, :].numpy(), axis=0))\n",
        "                # sanity check, if the range indeed contains a single word\n",
        "                if len(torch.unique(target[i, start_id: j, 1])) != 1:\n",
        "                    print(target[i, start_id: j, 0])\n",
        "                # if end of the utterance\n",
        "                if cur_w_id == -1:\n",
        "                    break\n",
        "                else:\n",
        "                    prev_w_id = cur_w_id\n",
        "                    start_id = j\n",
        "\n",
        "    valid_token_pred = np.array(valid_token_pred)\n",
        "    # this rounding is to solve the precision issue in the label\n",
        "    valid_token_target = np.array(valid_token_target).round(2)\n",
        "\n",
        "    mse_list, corr_list = [], []\n",
        "    # for each (accuracy, stress, total) word score\n",
        "    for i in range(3):\n",
        "        valid_token_mse = np.mean((valid_token_target[:, i] - valid_token_pred[:, i]) ** 2)\n",
        "        corr = np.corrcoef(valid_token_pred[:, i], valid_token_target[:, i])[0, 1]\n",
        "        mse_list.append(valid_token_mse)\n",
        "        corr_list.append(corr)\n",
        "    return mse_list, corr_list, valid_token_pred, valid_token_target"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjCZLezhvxfB",
        "outputId": "b47ef1ca-982e-4a68-b2ec-e94d47691b1c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I am process 538, running on 9604149c6b13: starting (Sun Sep 14 09:34:21 2025)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5. Train the model and see the results!\n",
        "Note: due to various reasons, the colab result will be slightly different with (but still very close to) that using the local script. E.g., in this run, we get 0.682 phone-level PCC, 0.600 word-level PCC, and 0.729 utterance-level PCC, while in the paper, we report 0.679. 0.601, and 0.731, respectively."
      ],
      "metadata": {
        "id": "UtIUrJo0OHEl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args = parser.parse_args(args=[])\n",
        "\n",
        "if torch.cuda.is_available() == False:\n",
        "    raise ValueError('GPU is not enabled. Please go to top menu - edit - notebook settings -hardware accelerator - GPU')\n",
        "\n",
        "am = args.am\n",
        "print('now train with {:s} acoustic models'.format(am))\n",
        "feat_dim = {'librispeech':84, 'paiia':86, 'paiib': 88}\n",
        "input_dim=feat_dim[am]\n",
        "\n",
        "# nowa is the best models used in this work\n",
        "if args.model == 'gopt':\n",
        "    print('now train a GOPT models')\n",
        "    audio_mdl = GOPT(embed_dim=args.embed_dim, num_heads=args.goptheads, depth=args.goptdepth, input_dim=input_dim)\n",
        "\n",
        "tr_dataset = GoPDataset('train', am=am)\n",
        "tr_dataloader = DataLoader(tr_dataset, batch_size=args.batch_size, shuffle=True)\n",
        "te_dataset = GoPDataset('test', am=am)\n",
        "te_dataloader = DataLoader(te_dataset, batch_size=2500, shuffle=False)\n",
        "\n",
        "if os.path.exists(args.exp_dir) == False:\n",
        "  os.makedirs(args.exp_dir)\n",
        "train(audio_mdl, tr_dataloader, te_dataloader, args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOEATqXrwkqn",
        "outputId": "b62bb9a7-765f-4edf-e52f-ec3f236fe0b8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "now train with paiia acoustic models\n",
            "now train a GOPT models\n",
            "running on cuda\n",
            "Total parameter number is : 26.625 k\n",
            "Total trainable parameter number is : 26.625 k\n",
            "current #steps=0, #epochs=0\n",
            "start training...\n",
            "start validation of epoch 0\n",
            "new best phn mse 0.109, now saving predictions.\n",
            "Phone: Test MSE: 0.109, CORR: 0.428\n",
            "Utterance:, ACC: -0.292, COM: 0.022, FLU: 0.289, PROC: 0.104, Total: -0.113\n",
            "Word:, ACC: 0.245, Stress: 0.073, Total: 0.219\n",
            "-------------------validation finished-------------------\n",
            "start validation of epoch 1\n",
            "new best phn mse 0.090, now saving predictions.\n",
            "Phone: Test MSE: 0.090, CORR: 0.536\n",
            "Utterance:, ACC: -0.082, COM: 0.023, FLU: 0.407, PROC: 0.475, Total: 0.184\n",
            "Word:, ACC: 0.445, Stress: 0.112, Total: 0.461\n",
            "-------------------validation finished-------------------\n",
            "start validation of epoch 2\n",
            "new best phn mse 0.087, now saving predictions.\n",
            "Phone: Test MSE: 0.087, CORR: 0.593\n",
            "Utterance:, ACC: 0.351, COM: 0.052, FLU: 0.556, PROC: 0.540, Total: 0.541\n",
            "Word:, ACC: 0.522, Stress: 0.121, Total: 0.548\n",
            "-------------------validation finished-------------------\n",
            "start validation of epoch 3\n",
            "new best phn mse 0.077, now saving predictions.\n",
            "Phone: Test MSE: 0.077, CORR: 0.635\n",
            "Utterance:, ACC: 0.652, COM: 0.114, FLU: 0.594, PROC: 0.575, Total: 0.654\n",
            "Word:, ACC: 0.562, Stress: 0.134, Total: 0.547\n",
            "-------------------validation finished-------------------\n",
            "start validation of epoch 4\n",
            "new best phn mse 0.073, now saving predictions.\n",
            "Phone: Test MSE: 0.073, CORR: 0.652\n",
            "Utterance:, ACC: 0.666, COM: 0.093, FLU: 0.600, PROC: 0.596, Total: 0.672\n",
            "Word:, ACC: 0.576, Stress: 0.094, Total: 0.556\n",
            "-------------------validation finished-------------------\n",
            "start validation of epoch 5\n",
            "new best phn mse 0.072, now saving predictions.\n",
            "Phone: Test MSE: 0.072, CORR: 0.660\n",
            "Utterance:, ACC: 0.677, COM: 0.040, FLU: 0.605, PROC: 0.591, Total: 0.685\n",
            "Word:, ACC: 0.575, Stress: 0.109, Total: 0.566\n",
            "-------------------validation finished-------------------\n",
            "start validation of epoch 6\n",
            "Phone: Test MSE: 0.072, CORR: 0.661\n",
            "Utterance:, ACC: 0.692, COM: 0.096, FLU: 0.626, PROC: 0.609, Total: 0.693\n",
            "Word:, ACC: 0.579, Stress: 0.145, Total: 0.583\n",
            "-------------------validation finished-------------------\n",
            "start validation of epoch 7\n",
            "Phone: Test MSE: 0.072, CORR: 0.667\n",
            "Utterance:, ACC: 0.689, COM: 0.041, FLU: 0.630, PROC: 0.618, Total: 0.700\n",
            "Word:, ACC: 0.586, Stress: 0.085, Total: 0.589\n",
            "-------------------validation finished-------------------\n",
            "start validation of epoch 8\n",
            "Phone: Test MSE: 0.073, CORR: 0.669\n",
            "Utterance:, ACC: 0.683, COM: 0.016, FLU: 0.617, PROC: 0.611, Total: 0.693\n",
            "Word:, ACC: 0.586, Stress: 0.089, Total: 0.590\n",
            "-------------------validation finished-------------------\n",
            "start validation of epoch 9\n",
            "new best phn mse 0.070, now saving predictions.\n",
            "Phone: Test MSE: 0.070, CORR: 0.674\n",
            "Utterance:, ACC: 0.699, COM: 0.026, FLU: 0.635, PROC: 0.624, Total: 0.704\n",
            "Word:, ACC: 0.580, Stress: 0.144, Total: 0.589\n",
            "-------------------validation finished-------------------\n",
            "start validation of epoch 10\n",
            "Phone: Test MSE: 0.073, CORR: 0.670\n",
            "Utterance:, ACC: 0.684, COM: 0.054, FLU: 0.611, PROC: 0.608, Total: 0.682\n",
            "Word:, ACC: 0.576, Stress: 0.161, Total: 0.588\n",
            "-------------------validation finished-------------------\n",
            "start validation of epoch 11\n",
            "new best phn mse 0.069, now saving predictions.\n",
            "Phone: Test MSE: 0.069, CORR: 0.679\n",
            "Utterance:, ACC: 0.706, COM: 0.022, FLU: 0.639, PROC: 0.631, Total: 0.707\n",
            "Word:, ACC: 0.588, Stress: 0.127, Total: 0.600\n",
            "-------------------validation finished-------------------\n",
            "start validation of epoch 12\n",
            "new best phn mse 0.068, now saving predictions.\n",
            "Phone: Test MSE: 0.068, CORR: 0.680\n",
            "Utterance:, ACC: 0.709, COM: 0.014, FLU: 0.646, PROC: 0.639, Total: 0.711\n",
            "Word:, ACC: 0.588, Stress: 0.129, Total: 0.600\n",
            "-------------------validation finished-------------------\n",
            "start validation of epoch 13\n",
            "Phone: Test MSE: 0.068, CORR: 0.681\n",
            "Utterance:, ACC: 0.707, COM: -0.044, FLU: 0.650, PROC: 0.639, Total: 0.713\n",
            "Word:, ACC: 0.594, Stress: 0.118, Total: 0.608\n",
            "-------------------validation finished-------------------\n",
            "start validation of epoch 14\n",
            "new best phn mse 0.068, now saving predictions.\n",
            "Phone: Test MSE: 0.068, CORR: 0.682\n",
            "Utterance:, ACC: 0.711, COM: 0.008, FLU: 0.648, PROC: 0.642, Total: 0.711\n",
            "Word:, ACC: 0.590, Stress: 0.126, Total: 0.605\n",
            "-------------------validation finished-------------------\n",
            "start validation of epoch 15\n",
            "new best phn mse 0.068, now saving predictions.\n",
            "Phone: Test MSE: 0.068, CORR: 0.683\n",
            "Utterance:, ACC: 0.715, COM: -0.019, FLU: 0.656, PROC: 0.647, Total: 0.718\n",
            "Word:, ACC: 0.593, Stress: 0.126, Total: 0.607\n",
            "-------------------validation finished-------------------\n",
            "start validation of epoch 16\n",
            "Phone: Test MSE: 0.068, CORR: 0.683\n",
            "Utterance:, ACC: 0.717, COM: -0.058, FLU: 0.658, PROC: 0.650, Total: 0.719\n",
            "Word:, ACC: 0.590, Stress: 0.132, Total: 0.605\n",
            "-------------------validation finished-------------------\n",
            "start validation of epoch 17\n",
            "Phone: Test MSE: 0.068, CORR: 0.682\n",
            "Utterance:, ACC: 0.717, COM: -0.013, FLU: 0.657, PROC: 0.650, Total: 0.718\n",
            "Word:, ACC: 0.589, Stress: 0.140, Total: 0.606\n",
            "-------------------validation finished-------------------\n",
            "start validation of epoch 18\n",
            "new best phn mse 0.068, now saving predictions.\n",
            "Phone: Test MSE: 0.068, CORR: 0.684\n",
            "Utterance:, ACC: 0.716, COM: -0.048, FLU: 0.660, PROC: 0.652, Total: 0.719\n",
            "Word:, ACC: 0.587, Stress: 0.130, Total: 0.602\n",
            "-------------------validation finished-------------------\n",
            "start validation of epoch 19\n",
            "Phone: Test MSE: 0.069, CORR: 0.681\n",
            "Utterance:, ACC: 0.716, COM: -0.023, FLU: 0.658, PROC: 0.652, Total: 0.718\n",
            "Word:, ACC: 0.585, Stress: 0.145, Total: 0.603\n",
            "-------------------validation finished-------------------\n",
            "start validation of epoch 20\n",
            "Phone: Test MSE: 0.068, CORR: 0.684\n",
            "Utterance:, ACC: 0.721, COM: -0.032, FLU: 0.662, PROC: 0.654, Total: 0.722\n",
            "Word:, ACC: 0.590, Stress: 0.125, Total: 0.604\n",
            "-------------------validation finished-------------------\n",
            "start validation of epoch 21\n",
            "Phone: Test MSE: 0.068, CORR: 0.683\n",
            "Utterance:, ACC: 0.718, COM: -0.065, FLU: 0.663, PROC: 0.656, Total: 0.721\n",
            "Word:, ACC: 0.587, Stress: 0.129, Total: 0.604\n",
            "-------------------validation finished-------------------\n",
            "start validation of epoch 22\n",
            "Phone: Test MSE: 0.069, CORR: 0.682\n",
            "Utterance:, ACC: 0.719, COM: -0.043, FLU: 0.662, PROC: 0.655, Total: 0.721\n",
            "Word:, ACC: 0.583, Stress: 0.141, Total: 0.599\n",
            "-------------------validation finished-------------------\n",
            "start validation of epoch 23\n",
            "Phone: Test MSE: 0.068, CORR: 0.685\n",
            "Utterance:, ACC: 0.714, COM: -0.081, FLU: 0.664, PROC: 0.656, Total: 0.720\n",
            "Word:, ACC: 0.589, Stress: 0.123, Total: 0.605\n",
            "-------------------validation finished-------------------\n",
            "start validation of epoch 24\n",
            "Phone: Test MSE: 0.068, CORR: 0.683\n",
            "Utterance:, ACC: 0.720, COM: -0.051, FLU: 0.665, PROC: 0.659, Total: 0.723\n",
            "Word:, ACC: 0.585, Stress: 0.138, Total: 0.601\n",
            "-------------------validation finished-------------------\n",
            "start validation of epoch 25\n",
            "Phone: Test MSE: 0.068, CORR: 0.683\n",
            "Utterance:, ACC: 0.719, COM: -0.064, FLU: 0.666, PROC: 0.660, Total: 0.723\n",
            "Word:, ACC: 0.586, Stress: 0.132, Total: 0.601\n",
            "-------------------validation finished-------------------\n",
            "start validation of epoch 26\n",
            "Phone: Test MSE: 0.068, CORR: 0.683\n",
            "Utterance:, ACC: 0.720, COM: -0.061, FLU: 0.666, PROC: 0.660, Total: 0.723\n",
            "Word:, ACC: 0.586, Stress: 0.135, Total: 0.602\n",
            "-------------------validation finished-------------------\n",
            "start validation of epoch 27\n",
            "new best phn mse 0.067, now saving predictions.\n",
            "Phone: Test MSE: 0.067, CORR: 0.685\n",
            "Utterance:, ACC: 0.721, COM: -0.074, FLU: 0.667, PROC: 0.660, Total: 0.724\n",
            "Word:, ACC: 0.589, Stress: 0.127, Total: 0.604\n",
            "-------------------validation finished-------------------\n",
            "start validation of epoch 28\n",
            "Phone: Test MSE: 0.067, CORR: 0.684\n",
            "Utterance:, ACC: 0.720, COM: -0.074, FLU: 0.668, PROC: 0.661, Total: 0.724\n",
            "Word:, ACC: 0.589, Stress: 0.127, Total: 0.605\n",
            "-------------------validation finished-------------------\n",
            "start validation of epoch 29\n",
            "Phone: Test MSE: 0.068, CORR: 0.683\n",
            "Utterance:, ACC: 0.720, COM: -0.073, FLU: 0.668, PROC: 0.662, Total: 0.724\n",
            "Word:, ACC: 0.585, Stress: 0.136, Total: 0.602\n",
            "-------------------validation finished-------------------\n",
            "start validation of epoch 30\n",
            "Phone: Test MSE: 0.068, CORR: 0.682\n",
            "Utterance:, ACC: 0.720, COM: -0.066, FLU: 0.668, PROC: 0.662, Total: 0.724\n",
            "Word:, ACC: 0.584, Stress: 0.139, Total: 0.601\n",
            "-------------------validation finished-------------------\n",
            "start validation of epoch 31\n",
            "new best phn mse 0.067, now saving predictions.\n",
            "Phone: Test MSE: 0.067, CORR: 0.685\n",
            "Utterance:, ACC: 0.721, COM: -0.080, FLU: 0.670, PROC: 0.663, Total: 0.725\n",
            "Word:, ACC: 0.588, Stress: 0.128, Total: 0.603\n",
            "-------------------validation finished-------------------\n",
            "start validation of epoch 32\n",
            "Phone: Test MSE: 0.068, CORR: 0.683\n",
            "Utterance:, ACC: 0.721, COM: -0.069, FLU: 0.669, PROC: 0.663, Total: 0.724\n",
            "Word:, ACC: 0.586, Stress: 0.136, Total: 0.602\n",
            "-------------------validation finished-------------------\n",
            "start validation of epoch 33\n",
            "Phone: Test MSE: 0.067, CORR: 0.685\n",
            "Utterance:, ACC: 0.718, COM: -0.090, FLU: 0.669, PROC: 0.662, Total: 0.724\n",
            "Word:, ACC: 0.591, Stress: 0.122, Total: 0.607\n",
            "-------------------validation finished-------------------\n",
            "start validation of epoch 34\n",
            "Phone: Test MSE: 0.067, CORR: 0.684\n",
            "Utterance:, ACC: 0.721, COM: -0.082, FLU: 0.670, PROC: 0.663, Total: 0.725\n",
            "Word:, ACC: 0.588, Stress: 0.129, Total: 0.604\n",
            "-------------------validation finished-------------------\n",
            "start validation of epoch 35\n",
            "Phone: Test MSE: 0.068, CORR: 0.684\n",
            "Utterance:, ACC: 0.722, COM: -0.079, FLU: 0.670, PROC: 0.664, Total: 0.725\n",
            "Word:, ACC: 0.587, Stress: 0.131, Total: 0.603\n",
            "-------------------validation finished-------------------\n",
            "start validation of epoch 36\n",
            "Phone: Test MSE: 0.067, CORR: 0.685\n",
            "Utterance:, ACC: 0.721, COM: -0.088, FLU: 0.670, PROC: 0.664, Total: 0.725\n",
            "Word:, ACC: 0.589, Stress: 0.126, Total: 0.604\n",
            "-------------------validation finished-------------------\n",
            "start validation of epoch 37\n",
            "Phone: Test MSE: 0.068, CORR: 0.684\n",
            "Utterance:, ACC: 0.722, COM: -0.085, FLU: 0.671, PROC: 0.664, Total: 0.725\n",
            "Word:, ACC: 0.587, Stress: 0.130, Total: 0.603\n",
            "-------------------validation finished-------------------\n",
            "start validation of epoch 38\n",
            "Phone: Test MSE: 0.067, CORR: 0.685\n",
            "Utterance:, ACC: 0.720, COM: -0.093, FLU: 0.671, PROC: 0.664, Total: 0.725\n",
            "Word:, ACC: 0.589, Stress: 0.126, Total: 0.605\n",
            "-------------------validation finished-------------------\n",
            "start validation of epoch 39\n",
            "Phone: Test MSE: 0.068, CORR: 0.684\n",
            "Utterance:, ACC: 0.722, COM: -0.083, FLU: 0.671, PROC: 0.664, Total: 0.726\n",
            "Word:, ACC: 0.586, Stress: 0.131, Total: 0.602\n",
            "-------------------validation finished-------------------\n",
            "start validation of epoch 40\n",
            "Phone: Test MSE: 0.068, CORR: 0.684\n",
            "Utterance:, ACC: 0.722, COM: -0.083, FLU: 0.671, PROC: 0.664, Total: 0.725\n",
            "Word:, ACC: 0.587, Stress: 0.130, Total: 0.603\n",
            "-------------------validation finished-------------------\n",
            "start validation of epoch 41\n",
            "Phone: Test MSE: 0.067, CORR: 0.685\n",
            "Utterance:, ACC: 0.721, COM: -0.090, FLU: 0.671, PROC: 0.664, Total: 0.726\n",
            "Word:, ACC: 0.588, Stress: 0.127, Total: 0.604\n",
            "-------------------validation finished-------------------\n",
            "start validation of epoch 42\n",
            "Phone: Test MSE: 0.067, CORR: 0.684\n",
            "Utterance:, ACC: 0.721, COM: -0.088, FLU: 0.671, PROC: 0.665, Total: 0.726\n",
            "Word:, ACC: 0.588, Stress: 0.128, Total: 0.604\n",
            "-------------------validation finished-------------------\n",
            "start validation of epoch 43\n",
            "Phone: Test MSE: 0.068, CORR: 0.684\n",
            "Utterance:, ACC: 0.722, COM: -0.085, FLU: 0.671, PROC: 0.665, Total: 0.726\n",
            "Word:, ACC: 0.587, Stress: 0.130, Total: 0.603\n",
            "-------------------validation finished-------------------\n",
            "start validation of epoch 44\n",
            "Phone: Test MSE: 0.068, CORR: 0.683\n",
            "Utterance:, ACC: 0.722, COM: -0.079, FLU: 0.671, PROC: 0.665, Total: 0.726\n",
            "Word:, ACC: 0.586, Stress: 0.132, Total: 0.602\n",
            "-------------------validation finished-------------------\n",
            "start validation of epoch 45\n",
            "Phone: Test MSE: 0.068, CORR: 0.684\n",
            "Utterance:, ACC: 0.722, COM: -0.085, FLU: 0.671, PROC: 0.665, Total: 0.726\n",
            "Word:, ACC: 0.587, Stress: 0.131, Total: 0.603\n",
            "-------------------validation finished-------------------\n",
            "start validation of epoch 46\n",
            "Phone: Test MSE: 0.068, CORR: 0.684\n",
            "Utterance:, ACC: 0.722, COM: -0.087, FLU: 0.671, PROC: 0.665, Total: 0.726\n",
            "Word:, ACC: 0.587, Stress: 0.130, Total: 0.603\n",
            "-------------------validation finished-------------------\n",
            "start validation of epoch 47\n",
            "Phone: Test MSE: 0.068, CORR: 0.684\n",
            "Utterance:, ACC: 0.722, COM: -0.086, FLU: 0.671, PROC: 0.665, Total: 0.726\n",
            "Word:, ACC: 0.587, Stress: 0.130, Total: 0.603\n",
            "-------------------validation finished-------------------\n",
            "start validation of epoch 48\n",
            "Phone: Test MSE: 0.067, CORR: 0.684\n",
            "Utterance:, ACC: 0.722, COM: -0.089, FLU: 0.672, PROC: 0.665, Total: 0.726\n",
            "Word:, ACC: 0.587, Stress: 0.129, Total: 0.603\n",
            "-------------------validation finished-------------------\n",
            "start validation of epoch 49\n",
            "Phone: Test MSE: 0.067, CORR: 0.684\n",
            "Utterance:, ACC: 0.722, COM: -0.089, FLU: 0.672, PROC: 0.665, Total: 0.726\n",
            "Word:, ACC: 0.588, Stress: 0.129, Total: 0.604\n",
            "-------------------validation finished-------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cài sox\n"
      ],
      "metadata": {
        "id": "r_ipn_hLkbEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "set -e\n",
        "apt-get -qq update\n",
        "apt-get -qq install -y sox libsox-fmt-all\n",
        "sox --version || true\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGCqaaykkUX5",
        "outputId": "67e38e6a-7424-4f45-9b20-51de6724ced1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting previously unselected package libao-common.\r\n",
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 126374 files and directories currently installed.)\r\n",
            "Preparing to unpack .../00-libao-common_1.2.2+20180113-1.1ubuntu3_all.deb ...\r\n",
            "Unpacking libao-common (1.2.2+20180113-1.1ubuntu3) ...\r\n",
            "Selecting previously unselected package libao4:amd64.\r\n",
            "Preparing to unpack .../01-libao4_1.2.2+20180113-1.1ubuntu3_amd64.deb ...\r\n",
            "Unpacking libao4:amd64 (1.2.2+20180113-1.1ubuntu3) ...\r\n",
            "Selecting previously unselected package libid3tag0:amd64.\r\n",
            "Preparing to unpack .../02-libid3tag0_0.15.1b-14_amd64.deb ...\r\n",
            "Unpacking libid3tag0:amd64 (0.15.1b-14) ...\r\n",
            "Selecting previously unselected package libmad0:amd64.\r\n",
            "Preparing to unpack .../03-libmad0_0.15.1b-10ubuntu1_amd64.deb ...\r\n",
            "Unpacking libmad0:amd64 (0.15.1b-10ubuntu1) ...\r\n",
            "Selecting previously unselected package libopencore-amrnb0:amd64.\r\n",
            "Preparing to unpack .../04-libopencore-amrnb0_0.1.5-1_amd64.deb ...\r\n",
            "Unpacking libopencore-amrnb0:amd64 (0.1.5-1) ...\r\n",
            "Selecting previously unselected package libopencore-amrwb0:amd64.\r\n",
            "Preparing to unpack .../05-libopencore-amrwb0_0.1.5-1_amd64.deb ...\r\n",
            "Unpacking libopencore-amrwb0:amd64 (0.1.5-1) ...\r\n",
            "Selecting previously unselected package libsox3:amd64.\r\n",
            "Preparing to unpack .../06-libsox3_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\r\n",
            "Unpacking libsox3:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\r\n",
            "Selecting previously unselected package libsox-fmt-alsa:amd64.\r\n",
            "Preparing to unpack .../07-libsox-fmt-alsa_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\r\n",
            "Unpacking libsox-fmt-alsa:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\r\n",
            "Selecting previously unselected package libsox-fmt-ao:amd64.\r\n",
            "Preparing to unpack .../08-libsox-fmt-ao_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\r\n",
            "Unpacking libsox-fmt-ao:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\r\n",
            "Selecting previously unselected package libwavpack1:amd64.\r\n",
            "Preparing to unpack .../09-libwavpack1_5.4.0-1build2_amd64.deb ...\r\n",
            "Unpacking libwavpack1:amd64 (5.4.0-1build2) ...\r\n",
            "Selecting previously unselected package libsox-fmt-base:amd64.\r\n",
            "Preparing to unpack .../10-libsox-fmt-base_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\r\n",
            "Unpacking libsox-fmt-base:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\r\n",
            "Selecting previously unselected package libsox-fmt-mp3:amd64.\r\n",
            "Preparing to unpack .../11-libsox-fmt-mp3_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\r\n",
            "Unpacking libsox-fmt-mp3:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\r\n",
            "Selecting previously unselected package libsox-fmt-oss:amd64.\r\n",
            "Preparing to unpack .../12-libsox-fmt-oss_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\r\n",
            "Unpacking libsox-fmt-oss:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\r\n",
            "Selecting previously unselected package libsox-fmt-pulse:amd64.\r\n",
            "Preparing to unpack .../13-libsox-fmt-pulse_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\r\n",
            "Unpacking libsox-fmt-pulse:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\r\n",
            "Selecting previously unselected package libsox-fmt-all:amd64.\r\n",
            "Preparing to unpack .../14-libsox-fmt-all_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\r\n",
            "Unpacking libsox-fmt-all:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\r\n",
            "Selecting previously unselected package sox.\r\n",
            "Preparing to unpack .../15-sox_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\r\n",
            "Unpacking sox (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\r\n",
            "Setting up libsox3:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\r\n",
            "Setting up libsox-fmt-oss:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\r\n",
            "Setting up libao-common (1.2.2+20180113-1.1ubuntu3) ...\r\n",
            "Setting up libid3tag0:amd64 (0.15.1b-14) ...\r\n",
            "Setting up libopencore-amrwb0:amd64 (0.1.5-1) ...\r\n",
            "Setting up libsox-fmt-alsa:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\r\n",
            "Setting up libao4:amd64 (1.2.2+20180113-1.1ubuntu3) ...\r\n",
            "Setting up libmad0:amd64 (0.15.1b-10ubuntu1) ...\r\n",
            "Setting up libwavpack1:amd64 (5.4.0-1build2) ...\r\n",
            "Setting up libopencore-amrnb0:amd64 (0.1.5-1) ...\r\n",
            "Setting up libsox-fmt-base:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\r\n",
            "Setting up libsox-fmt-ao:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\r\n",
            "Setting up libsox-fmt-mp3:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\r\n",
            "Setting up libsox-fmt-pulse:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\r\n",
            "Setting up sox (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\r\n",
            "Setting up libsox-fmt-all:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\r\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\r\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\r\n",
            "\r\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\r\n",
            "\r\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\r\n",
            "\r\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\r\n",
            "\r\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\r\n",
            "\r\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\r\n",
            "\r\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\r\n",
            "\r\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\r\n",
            "\r\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\r\n",
            "\r\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\r\n",
            "\r\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\r\n",
            "\r\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\r\n",
            "\r\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\r\n",
            "\r\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\r\n",
            "\r\n",
            "Processing triggers for man-db (2.10.2-1) ...\r\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\r\n",
            "sox:      SoX v14.4.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload & chuẩn hoá WAV (có fallback nếu thiếu sox)"
      ],
      "metadata": {
        "id": "u71i9HTakqM2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# U1-ALT: NHẬP WORD & UPLOAD .WAV, CHUẨN HOÁ -> 16 kHz MONO\n",
        "from google.colab import files\n",
        "import os, subprocess, math\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "from scipy.signal import resample_poly\n",
        "\n",
        "# ĐIỀN TỪ CỦA BẠN (IN HOA). Ví dụ bạn dùng: REFERENCE\n",
        "WORD = \"REFERENCE\"\n",
        "\n",
        "uploaded = files.upload()  # chọn file .wav (vd: utt001.wav)\n",
        "WAV_PATH = next(k for k in uploaded if k.lower().endswith(\".wav\"))\n",
        "print(\"WORD:\", WORD, \"| WAV:\", WAV_PATH)\n",
        "\n",
        "def convert_to_16k_mono(in_path, out_path):\n",
        "    # 1) Thử dùng sox nếu có\n",
        "    try:\n",
        "        subprocess.run([\"bash\",\"-lc\",\"sox --version\"], check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "        subprocess.run([\"bash\",\"-lc\", f\"sox '{in_path}' -r 16000 -c 1 '{out_path}'\"], check=True)\n",
        "        return out_path\n",
        "    except Exception as e:\n",
        "        # 2) Fallback thuần Python: soundfile + resample_poly\n",
        "        data, sr = sf.read(in_path, always_2d=False)\n",
        "        # về mono\n",
        "        if data.ndim > 1:\n",
        "            data = data.mean(axis=1)\n",
        "        # resample về 16k\n",
        "        if sr != 16000:\n",
        "            g = math.gcd(sr, 16000)\n",
        "            up, down = 16000 // g, sr // g\n",
        "            data = resample_poly(data, up, down)\n",
        "            sr = 16000\n",
        "        sf.write(out_path, data, sr)\n",
        "        return out_path\n",
        "\n",
        "out_wav = WAV_PATH + \".16k.wav\"\n",
        "WAV_PATH = convert_to_16k_mono(WAV_PATH, out_wav)\n",
        "print(\"WAV chuẩn hoá:\", WAV_PATH)\n",
        "\n",
        "# Kiểm tra lại thuộc tính file\n",
        "info = sf.info(WAV_PATH)\n",
        "print(\"Sample rate:\", info.samplerate, \"| Channels:\", info.channels, \"| Frames:\", info.frames)\n",
        "assert info.samplerate == 16000 and info.channels == 1, \"WAV chưa phải 16k mono.\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "UAgaM-kzkgiz",
        "outputId": "f0cf4f6a-6f69-442d-e668-03d7f12f958a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a1c622e0-6f29-4591-8101-ce74cfd0ce36\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a1c622e0-6f29-4591-8101-ce74cfd0ce36\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving utt001.wav to utt001 (2).wav\n",
            "WORD: REFERENCE | WAV: utt001 (2).wav\n",
            "WAV chuẩn hoá: utt001 (2).wav.16k.wav\n",
            "Sample rate: 16000 | Channels: 1 | Frames: 55520\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# U2: TẠO data & text-phone cho test_dataset\n",
        "import os, urllib.request, shutil\n",
        "\n",
        "BASE = \"/content/kaldi/egs/gop_speechocean762_work/s5\"  # đổi nếu bạn để nơi khác\n",
        "\n",
        "# 1) copy wav vào WAVE/SPEAKER0001/test.wav\n",
        "os.makedirs(os.path.join(BASE,\"WAVE\",\"SPEAKER0001\"), exist_ok=True)\n",
        "shutil.copyfile(WAV_PATH, os.path.join(BASE,\"WAVE\",\"SPEAKER0001\",\"test.wav\"))\n",
        "\n",
        "# 2) ghi các file bắt buộc cho train/test\n",
        "droot = os.path.join(BASE,\"data\",\"test_dataset\")\n",
        "for split in (\"train\",\"test\"):\n",
        "    dd = os.path.join(droot, split); os.makedirs(dd, exist_ok=True)\n",
        "    open(os.path.join(dd,\"wav.scp\"),\"w\").write(\"test\\tWAVE/SPEAKER0001/test.wav\\n\")\n",
        "    open(os.path.join(dd,\"utt2spk\"),\"w\").write(\"test 0001\\n\")\n",
        "    open(os.path.join(dd,\"spk2utt\"),\"w\").write(\"0001 test\\n\")\n",
        "    open(os.path.join(dd,\"text\"),\"w\").write(f\"test {WORD}\\n\")\n",
        "\n",
        "# 3) tạo lexicon + text-phone (B/I/E/S) từ Librispeech lexicon\n",
        "lex_local = \"/content/librispeech-lexicon.txt\"\n",
        "if not os.path.exists(lex_local):\n",
        "    urllib.request.urlretrieve(\"http://www.openslr.org/resources/11/librispeech-lexicon.txt\", lex_local)\n",
        "\n",
        "lexicon_dict_l = {}\n",
        "with open(lex_local, \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        parts = line.strip().split()\n",
        "        if not parts: continue\n",
        "        key = parts[0].upper(); phs = parts[1:]\n",
        "        if len(phs)==1:\n",
        "            phs[0] += \"_S\"\n",
        "        elif len(phs)>=2:\n",
        "            phs[0] += \"_B\"; phs[-1] += \"_E\"\n",
        "            for i in range(1, len(phs)-1): phs[i] += \"_I\"\n",
        "        lexicon_dict_l[key] = \" \".join(phs)\n",
        "\n",
        "assert WORD in lexicon_dict_l, f\"Từ {WORD} chưa có trong lexicon.\"\n",
        "\n",
        "res_dir = os.path.join(BASE,\"resource\"); os.makedirs(res_dir, exist_ok=True)\n",
        "with open(os.path.join(res_dir,\"lexicon.txt\"),\"w\") as f:\n",
        "    for k,v in lexicon_dict_l.items(): f.write(f\"{k} {v}\\n\")\n",
        "with open(os.path.join(res_dir,\"text-phone\"),\"w\") as f:\n",
        "    f.write(f\"test.0\\t{lexicon_dict_l[WORD]}\\n\")\n",
        "\n",
        "print(\"✓ Data & text-phone sẵn sàng cho:\", WORD)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tXLiCY5k4Bv",
        "outputId": "2a3f4775-998b-4b5f-aa51-9ed2fc1dfd30"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Data & text-phone sẵn sàng cho: REFERENCE\n"
          ]
        }
      ]
    }
  ]
}